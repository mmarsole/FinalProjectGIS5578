{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: create viewsheds based on 6 image locations\n",
    "1. Load Data\n",
    "    * DEMS\n",
    "    * GPS csv file\n",
    "2. Convert csv file to coordinates\n",
    "3. Convert GPS coordinates (a feature layer) to shp\n",
    "4. Create individual shps for each image point\n",
    "    * Extract relevant values for names (names for new shapefiles)\n",
    "    * Create 6 copies of the GPS shp (containing all data) and delete all rows expt 1 point (then save shp)\n",
    "5. Use Viewshed() to calculate viewshed rasters for each image\n",
    "\n",
    "\n",
    "<i>Please Note this Notebook was completed within an ArcGIS Pro environment with access to Arcpy</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system modules\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Creating Variables for Project ##################################################\n",
    "# adjust to accurate location of files\n",
    "GPS_csv_Filepath = r\"C:\\Users\\runac\\Downloads\\Fall_2022\\Programming\\project_idea\\JupNotebooks\\GPS_metadata.csv\"\n",
    "DEM_Filepath = r\"D:\\Fall_2022\\Programming\\Project\\Data\\30DEM\\USGS_1_n49w114_20210607.tif\"\n",
    "Output_Filepath = \"D:\\Fall_2022\\Programming\\Project\\Viewshed_MT_cleaner\\Viewshed_MT_cleaner.gdb\"\n",
    "#saving files to a NON .gdb directory\n",
    "out_path = r\"D:\\Fall_2022\\Programming\\Project\\Viewshed_MT_cleaner\"\n",
    "Num_Image_Coords = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring functions used throughout this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creating_file_names(path, filename_str, length):\n",
    "    \"\"\"\n",
    "    Provide the path where you'd like to save each file, and the naming string used to name resulting files\n",
    "    filename_str needs to be formatted as \"\\<filename>\", and the supplied path must use '\\' \n",
    "    \n",
    "    Returns a sequential numbered list of filename paths for the provided length \n",
    "    (length = number of image coordinates being used to create viewsheds)\n",
    "    \"\"\"\n",
    "    path_ = path\n",
    "    list_ = []\n",
    "    for number in range(length): \n",
    "        filename = filename_str + str(number + 1)\n",
    "        list_.append(path_ + filename)\n",
    "    \n",
    "    return list_\n",
    "\n",
    "#################### Connect image.shp point to each of the points on circle perimeter creating a new polyline shapefile #########\n",
    "# create a def to be called later that extracts the coordinates for each image.shp\n",
    "def get_image_coords(path_to_image):\n",
    "    '''\n",
    "    Given the shapefile path you can extract the points coorndinates. \n",
    "    Note: this function assumes provided shapefile is 1 point, thus it only returns 1 point value, \n",
    "    if shapefile has many pts, funtion will return last pt\n",
    "    \n",
    "    Returns an arcpy Point\n",
    "    '''\n",
    "    with arcpy.da.SearchCursor(path_to_image, ['*']) as cursor:\n",
    "        for row in cursor:\n",
    "            cp = arcpy.Point(row[1][0], row[1][1])\n",
    "    return cp\n",
    "\n",
    "def creating_polylines(filepath, anchor_point, connection_points, percentage_increment): \n",
    "    \"\"\"\n",
    "    Creates lines from each coordinate (image<#>.shp) to the points plotted on the minimum bounding circle \n",
    "    created around the viewshed. \n",
    "    \n",
    "    filepath: insert desired name for each polyline file created with entire filepath (to .gdb)\n",
    "    anchor_point: filepath to shapefile for each respective image's coordinates\n",
    "    connection_points: filepath to the points created on the minimum bounding circle\n",
    "    percentage_increment: dictates the frequency/ interval of the points plotted around the minimum bounding circle.\n",
    "    The samller the number the more points. Must be a value between 0 and 100. \n",
    "    (makes sure this 'percentage_increment' = 'Percentage' in \"GeneratePointsAlongLines()\")\n",
    "    \n",
    "    Returns a new shapefile made of polylines labeled by \"Degree\" column\n",
    "    \"\"\"\n",
    "    # creating new file name and shapefile for polylines\n",
    "    new_fc = filepath\n",
    "    name = filepath[(len(Output_Filepath)+1):len(filepath)]\n",
    "    # matching the spatial refernce of the DEM file\n",
    "    sr = arcpy.SpatialReference(4269) \n",
    "    arcpy.management.CreateFeatureclass(Output_Filepath, name, 'POLYLINE', spatial_reference = sr)\n",
    "    # ADDing a column that designates degree (I believe arc designates N as 0 and rotates clockwise)\n",
    "    arcpy.management.AddField(name, \"Degree\", \"DOUBLE\", None, None, None, \"Degree\", \"NULLABLE\", \"NON_REQUIRED\", '')\n",
    "\n",
    "    percentage = 0\n",
    "    \n",
    "    # Creating a line for each point on perimeter to corresponding image\n",
    "    # looping through perimeter points\n",
    "    with arcpy.da.SearchCursor(connection_points, ['*']) as cursor:\n",
    "        for row in cursor:\n",
    "            list_points = arcpy.Array([])\n",
    "            # calulating the degree sequentially clockwise (adjust percentage if GeneratePointsAlongLines() uses differnt percentage)\n",
    "            degree = (percentage/100)*360\n",
    "            \n",
    "            # declaring start (image location) & end (pts on circle) points for each line\n",
    "            cp1 = get_image_coords(anchor_point) #pulling the same image point\n",
    "            cp2 = arcpy.Point(row[1][0], row[1][1])\n",
    "            list_points.append(cp2)\n",
    "            list_points.append(cp1)\n",
    "            \n",
    "            # assignng spatial reference (should check to make sure its accurate)\n",
    "            spatial_reference = arcpy.SpatialReference(4326)\n",
    "            polyline = arcpy.Polyline(list_points, spatial_reference)\n",
    "           \n",
    "            # inserting new line to new feature class\n",
    "            with arcpy.da.InsertCursor(new_fc, [\"SHAPE@\", \"Degree\"]) as icur:\n",
    "                icur.insertRow([polyline, degree])\n",
    "                del icur\n",
    "            \n",
    "            # updating percentage for each line\n",
    "            percentage += percentage_increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1.HEIC\n",
      "image2.HEIC\n",
      "image3.HEIC\n",
      "image4.JPG\n",
      "image5.JPG\n",
      "image8.JPG\n"
     ]
    }
   ],
   "source": [
    "########################################## Loading DEM and GPS data ###########################################################\n",
    "# (steps 1-4)\n",
    "# relevant rasters needed for the viewshed...\n",
    "DEM1 = Raster(DEM_Filepath)\n",
    "# pre-defining spatial refernce\n",
    "# spatial_ref = arcpy.Describe(GPS_csv_Filepath).spatialReference\n",
    "spatial_ref = arcpy.SpatialReference(4326)\n",
    "\n",
    "# convert the csv table to points (run once)\n",
    "arcpy.management.XYTableToPoint(GPS_csv_Filepath, \n",
    "                                r\"GPS_metadata_XYTableToPoint\", \n",
    "                                \"decimal_Long\", \n",
    "                                \"decimal_Lat\",\n",
    "                                \"GPSAltitude\", \n",
    "                                spatial_ref)\n",
    "\n",
    "# converting GPS data to a shp\n",
    "arcpy.conversion.FeatureClassToShapefile(\"GPS_metadata_XYTableToPoint\", Output_Filepath)\n",
    "\n",
    "# creating a list that stores the name of each image file (used later to create individual shp for each point)\n",
    "List_shp = []\n",
    "List_names = []\n",
    "with arcpy.da.UpdateCursor(\"GPS_metadata_XYTableToPoint\", ['Field1']) as cursor:\n",
    "    for row in cursor:\n",
    "        print(row[0])\n",
    "        name = row[0].split('.')\n",
    "        List_shp.append(f'{name[0]}.shp')\n",
    "        List_names.append(row[0])\n",
    "        \n",
    "# copying featureclass and converting to individual shpfiles for each point\n",
    "data = Output_Filepath + \"\\GPS_metadata_XYTableToPoint\"\n",
    "count = 0\n",
    "for name in List_shp:\n",
    "    # copying original file \n",
    "    arcpy.management.CopyFeatures(data, name)\n",
    "    # creating shpfiles with 1 point by deleting all features excepts for 1 row\n",
    "    with arcpy.da.UpdateCursor(name, ['Field1','decimal_La','decimal_Lo', 'GPSAltit_1']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] != List_names[count]:\n",
    "                cursor.deleteRow()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving outvwdshd1\n",
      "saving outvwdshd2\n",
      "saving outvwdshd3\n",
      "saving outvwdshd4\n",
      "saving outvwdshd5\n",
      "saving outvwdshd6\n"
     ]
    }
   ],
   "source": [
    "############### Creating a list of names to use for viewsheds, based on the number of images processed ###################\n",
    "# (step 5)\n",
    "# declaring lists for names and creating files for Viewshed Outputs\n",
    "List_Raster_V_names = Creating_file_names(Output_Filepath, \"\\outvwdshd\", Num_Image_Coords)\n",
    "List_outnames = Creating_file_names(Output_Filepath, \"\\outViewshed\", Num_Image_Coords)\n",
    "\n",
    "###################################################### VIEWSHED ############################################################\n",
    "for shp, out_file, vwshd in zip(List_shp, List_outnames, List_Raster_V_names):\n",
    "    # Execute Viewshed (DON'T NEED 'List_Raster_V_names')\n",
    "    outViewshed = Viewshed(DEM1, shp, 1, \"FLAT_EARTH\", 0.13)\n",
    "    # Save the output \n",
    "    outViewshed.save(out_file)\n",
    "    name = vwshd[(len(Output_Filepath)+1):len(vwshd)]\n",
    "    print(\"saving\", name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next big step: extracting elevation values (maxes) in a 360 view around image points. \n",
    "\n",
    "1. Viewshed raster to Polygon\n",
    "2. Create a minimum bounding circle on vectorized viewshed raster\n",
    "3. Generate points on perimeter of circle (min bounding region)\n",
    "4. Connect image.shp point to each of the points on circle perimeter creating a new polyline shapefile.\n",
    "5. Use vectorized viewshed raster to mask DEM (resulting in a viewshed shaped DEM with real elevation values)\n",
    "6. Extract the cell values from the clipped viewshed DEM with the Polylines. \n",
    "    * For each line store the largest DEM value and save values in a table\n",
    "7. Plot table (in LATIS see Visualization_elev_dist.ipynb notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving & Updating: Poly_outView1\n",
      "Saving & Updating: Poly_outView2\n",
      "Saving & Updating: Poly_outView3\n",
      "Saving & Updating: Poly_outView4\n",
      "Saving & Updating: Poly_outView5\n",
      "Saving & Updating: Poly_outView6\n"
     ]
    }
   ],
   "source": [
    "################################################## Viewshed raster to Polygon ########################################\n",
    "# vectorizing resulting viewshed rasters\n",
    "\n",
    "# list of names for the viewshed tifs\n",
    "vwshd_tifs = Creating_file_names(Output_Filepath, \"\\outViewshed\", Num_Image_Coords)\n",
    "# list of names to be used for vectorized viewsheds\n",
    "ras_to_polys = Creating_file_names(Output_Filepath, \"\\Poly_outView\", Num_Image_Coords)\n",
    "\n",
    "# Looping over \"ras_to_polys\" to convert ALL viewsheds to polygons\n",
    "for tif, poly in zip(vwshd_tifs, ras_to_polys):\n",
    "    # isolating names of tif file from rest of path\n",
    "    name = tif[(len(Output_Filepath)+ 1):len(tif)]\n",
    "    # converting rasters to polygons\n",
    "    arcpy.conversion.RasterToPolygon(name, \n",
    "                                     poly, \n",
    "                                     \"SIMPLIFY\", \n",
    "                                     \"Value\", \n",
    "                                     \"SINGLE_OUTER_PART\", \n",
    "                                     None)\n",
    "\n",
    "# deleting polygons with gridcode = 0 (represents areas viewer cannot see)\n",
    "for v in ras_to_polys: \n",
    "    with arcpy.da.UpdateCursor(v, ['*']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[3] == 0:\n",
    "                cursor.deleteRow()\n",
    "    print(\"Saving & Updating:\", v[(len(Output_Filepath)+1):len(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving B_outView1\n",
      "Saving B_outView2\n",
      "Saving B_outView3\n",
      "Saving B_outView4\n",
      "Saving B_outView5\n",
      "Saving B_outView6\n"
     ]
    }
   ],
   "source": [
    "########################### create a min bounding circle on vectorized viewshed raster #######################\n",
    "# creating list of names for minimum bounding circles\n",
    "min_bound_names = Creating_file_names(Output_Filepath, \"\\B_outView\", Num_Image_Coords)\n",
    "\n",
    "# creating minimum bounding circle around viewshds\n",
    "for poly_vwshd, min_bound in zip(ras_to_polys, min_bound_names):\n",
    "    arcpy.management.MinimumBoundingGeometry(poly_vwshd, \n",
    "                                         min_bound, \n",
    "                                         \"CIRCLE\", \n",
    "                                         \"ALL\")\n",
    "    print(\"Saving\", min_bound[(len(Output_Filepath)+1):len(min_bound)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Pts_View1\n",
      "Saving Pts_View2\n",
      "Saving Pts_View3\n",
      "Saving Pts_View4\n",
      "Saving Pts_View5\n",
      "Saving Pts_View6\n"
     ]
    }
   ],
   "source": [
    "############################## Generate points on perimeter of circle (min bounding region) ######################\n",
    "# creating list of names for points on minimum bouding circles\n",
    "pts_names = Creating_file_names(Output_Filepath, \"\\Pts_View\", Num_Image_Coords)\n",
    "\n",
    "# creating pts on minimum bounding circle\n",
    "for circle, pts in zip(min_bound_names, pts_names):\n",
    "    arcpy.management.GeneratePointsAlongLines(circle, \n",
    "                                          pts, \n",
    "                                          \"PERCENTAGE\",  \n",
    "                                          Percentage=0.2, \n",
    "                                          Include_End_Points='END_POINTS')\n",
    "    \n",
    "    print(\"Saving\", pts[(len(Output_Filepath)+1):len(pts)])\n",
    "\n",
    "    # takes apporx 2-3 mins to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: View_lines1\n",
      "Creating: View_lines2\n",
      "Creating: View_lines3\n",
      "Creating: View_lines4\n",
      "Creating: View_lines5\n",
      "Creating: View_lines6\n"
     ]
    }
   ],
   "source": [
    "#################### Connect image.shp point to each of the points on circle perimeter creating a new polyline shapefile ##########\n",
    "\n",
    "# creating paths and names for new polyline files \n",
    "polyline_names = Creating_file_names(Output_Filepath, \"\\View_lines\", Num_Image_Coords)\n",
    "\n",
    "# polyline_names : recently declared above\n",
    "# pts_names : calling this already made list of minimum bounding circle pts\n",
    "# List_shp : calling this already made list of image locations \n",
    "\n",
    "# Running the function that'll create polylines for each image and corresponding viewshed points\n",
    "for polyline, image, pts, in zip(polyline_names, List_shp, pts_names):\n",
    "    print(\"Creating:\", polyline[(len(Output_Filepath) + 1):len(polyline)])\n",
    "    creating_polylines(polyline, image, pts, 0.2)\n",
    "    \n",
    "# takes 1.5 mins to make lines when p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping: Clipped_DEM_Vwshd1\n",
      "Clipping: Clipped_DEM_Vwshd2\n",
      "Clipping: Clipped_DEM_Vwshd3\n",
      "Clipping: Clipped_DEM_Vwshd4\n",
      "Clipping: Clipped_DEM_Vwshd5\n",
      "Clipping: Clipped_DEM_Vwshd6\n"
     ]
    }
   ],
   "source": [
    "########################################## Use vectorized viewshed raster to mask DEM ###################################\n",
    "# creating paths and names for new clipped DEM of viewsheds \n",
    "c_DEM_names = Creating_file_names(Output_Filepath, \"\\Clipped_DEM_Vwshd\", Num_Image_Coords)\n",
    "\n",
    "# declaring the spatial extent of the DEM1 (used to help clip the DEM to the viewshed output)\n",
    "extent = DEM1.extent\n",
    "xmin = extent.XMin\n",
    "ymin = extent.YMin\n",
    "xmax = extent.XMax\n",
    "ymax = extent.YMax\n",
    "spatial_extent = str(xmin) + \" \" + str(ymin) +  \" \" + str(xmax) +  \" \" +str(ymax)\n",
    "\n",
    "# creating a clipped extent of DEM for each image\n",
    "for vwshd, clip_dem in zip(ras_to_polys, c_DEM_names):\n",
    "    print(\"Clipping:\", clip_dem[(len(Output_Filepath)+1):len(clip_dem)])\n",
    "    poly_vwshd = vwshd[(len(Output_Filepath)+1):len(vwshd)]\n",
    "    arcpy.management.Clip(DEM1, \n",
    "                          spatial_extent,\n",
    "                          clip_dem, \n",
    "                          poly_vwshd, \n",
    "                          \"-999999\", \n",
    "                          \"ClippingGeometry\", \n",
    "                          \"NO_MAINTAIN_EXTENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Int_clip_DEM_Vwshd1\n",
      "Saving Int_clip_DEM_Vwshd2\n",
      "Saving Int_clip_DEM_Vwshd3\n",
      "Saving Int_clip_DEM_Vwshd4\n",
      "Saving Int_clip_DEM_Vwshd5\n",
      "Saving Int_clip_DEM_Vwshd6\n",
      "Saving Max Elevation value\n",
      "Saving Max Elevation value\n",
      "Saving Max Elevation value\n",
      "Saving Max Elevation value\n",
      "Saving Max Elevation value\n",
      "Saving Max Elevation value\n"
     ]
    }
   ],
   "source": [
    "############### Extract the Elevation values from the clipped viewshed DEM with the Polylines ############\n",
    "# creating paths and names for new INTIGER-(datatype) clipped DEM of viewsheds \n",
    "int_DEM_names = Creating_file_names(Output_Filepath, \"\\Int_clip_DEM_Vwshd\", Num_Image_Coords)\n",
    "poly_pixels_vw = Creating_file_names(Output_Filepath, \"\\Poly_Int_Clip_DEM\", Num_Image_Coords)\n",
    "max_elevation = Creating_file_names(Output_Filepath, \"\\lines_max_elev\", Num_Image_Coords)\n",
    "\n",
    "# convert elevation datatype from decimal to integer (looses some data)\n",
    "for clip_dem, int_dem in zip(c_DEM_names, int_DEM_names):\n",
    "    print(\"Saving\", int_dem[(len(Output_Filepath)+1):len(int_dem)])\n",
    "    out_raster = arcpy.ia.Int(clip_dem[(len(Output_Filepath)+1):len(clip_dem)]); out_raster.save(int_dem)\n",
    "\n",
    "# convert raster to polygons (s.t. each raster pixel is a polygon)\n",
    "for int_dem, poly_dem in zip(int_DEM_names, poly_pixels_vw):\n",
    "    arcpy.conversion.RasterToPolygon(int_dem[(len(Output_Filepath)+1):len(int_dem)], \n",
    "                                     poly_dem, \n",
    "                                     \"NO_SIMPLIFY\", \n",
    "                                     \"Value\", \n",
    "                                     \"SINGLE_OUTER_PART\", \n",
    "                                     None)\n",
    "\n",
    "# spatial join between pixels (as polygons) and polylines : whilst saving only max elevations for each polyline\n",
    "# this join returns the max 'gridcode' ('elevation value') that intersects with a line!!\n",
    "for lines, poly_dem, elev in zip(polyline_names, poly_pixels_vw, max_elevation):\n",
    "    arcpy.analysis.SpatialJoin(lines[(len(Output_Filepath)+1):len(lines)], \n",
    "                               poly_dem[(len(Output_Filepath)+1):len(poly_dem)], \n",
    "                               elev, \n",
    "                               \"JOIN_ONE_TO_ONE\", \n",
    "                               \"KEEP_ALL\", \n",
    "                               'Degree \"Degree\" true true false 19 Double 0 0,First,#,view1_lines_b,Degree,-1,-1;'\\\n",
    "                               'gridcode \"gridcode\" true true false 4 Long 0 0,Max,#,Poly_Int_Clip_DEM1,gridcode,-1,-1', \n",
    "                               \"INTERSECT\", \n",
    "                               None, \n",
    "                               '')\n",
    "    print(\"Saving Max Elevation value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: lines_max_elev1.csv\n",
      "Saving: lines_max_elev2.csv\n",
      "Saving: lines_max_elev3.csv\n",
      "Saving: lines_max_elev4.csv\n",
      "Saving: lines_max_elev5.csv\n",
      "Saving: lines_max_elev6.csv\n"
     ]
    }
   ],
   "source": [
    "# exported the shp as a csv to view in LATIS\n",
    "# exporting csv files to a NON gdb directoy\n",
    "csv_names = Creating_file_names(out_path, \"\\lines_max_elev\", Num_Image_Coords)\n",
    "\n",
    "for elev, csv in zip(max_elevation, csv_names):\n",
    "    name = csv + \".csv\"\n",
    "    print(\"Saving:\", name[(len(out_path)+1):(len(csv)+4)])\n",
    "    arcpy.conversion.ExportTable(elev[(len(Output_Filepath)+1):len(elev)], \n",
    "                                 name, \n",
    "                                 '', \n",
    "                                 \"NOT_USE_ALIAS\", \n",
    "                                 'Join_Count \"Join_Count\" true true false 4 Long 0 0,First,#,view1_lines_b_SpatialJoin2,Join_Count,-1,-1;'\\\n",
    "                                 'TARGET_FID \"TARGET_FID\" true true false 4 Long 0 0,First,#,view1_lines_b_SpatialJoin2,TARGET_FID,-1,-1;'\\\n",
    "                                 'Degree \"Degree\" true true false 8 Double 0 0,First,#,view1_lines_b_SpatialJoin2,Degree,-1,-1;'\\\n",
    "                                 'gridcode \"gridcode\" true true false 4 Long 0 0,First,#,view1_lines_b_SpatialJoin2,gridcode,-1,-1', \n",
    "                                 None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After successfully extrating the Max elevation values for each polyline, I need to measure distance from observer/image pt to location of Max elevation pixel. I then need to create new values where max elevation is divided by distance (to accurately depict a mountain ridgeline w.r.t. distance) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Big Step: Calculate Distance from image/anchor pt to each Max Elevation \n",
    "\n",
    "1. Spatial Join between vectorized clipped DEM from viewshed and the polylines generated from image to min bounding pts\n",
    "    * retain polygon (pixel) geometry\n",
    "    * make sure it retains only MAX elevation polygon per line\n",
    "2. Clip or divide the Polylines with the geom returned from previous step. \n",
    "    * retain only lines that intersect with image/anchor point\n",
    "3. Measure the line length (Use \"Calculate Geometry Attributes\" tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining more functions used in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Only working way to indentify MAX for each polyline... #######################################\n",
    "# identifying the max elevation for each polyline and saving the polygon OBJECTID, coords, and elevation to a dictionary\n",
    "\n",
    "def Identifying_Max_elevations_from_Poly_Pixels(line_geom, poly_pixel_geom):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that identifes the vectorized pixels that contain the MAX elevation for each polyline. \n",
    "    dictionary format: max_dict[Degree] = [pixel_ID, coords (lat,long), Max_Elevation]\n",
    "    Assumes that the \"poly_pixel_geom\" feature always ahs the same columns in a certain order (will extract worng values \n",
    "    if columns are not the same for all geoms)\n",
    "    \"\"\"\n",
    "    max_dict = {}\n",
    "    counter = 0\n",
    "    # For each line:\n",
    "    with arcpy.da.SearchCursor(line_geom, ['Degree']) as cursor:\n",
    "        for line in cursor:\n",
    "            ID = line[0] # make sure to grab \"Degree\" so as to match unique values later\n",
    "        # iterate over corresponding pixels that match each line (through 'ID' column)\n",
    "            with arcpy.da.SearchCursor(poly_pixel_geom, ['*']) as cur:\n",
    "                Max_ = 0\n",
    "                obj_id = 0\n",
    "                coords = 0\n",
    "                for pixel in cur:\n",
    "                    counter += 1\n",
    "                    # make sure these indeces match correct columns!!\n",
    "                    if pixel[6] == ID:\n",
    "                        if Max_ < pixel[5]:\n",
    "                            Max_ = pixel[5]\n",
    "                            obj_id = pixel[3] #target_ID\n",
    "                            coords = pixel[1]\n",
    "                        max_dict[ID] = [obj_id, coords, Max_]\n",
    "    print(\"Done Creating Max Dict. Iterated\", counter, \"times (lines x pixels in each viewshed)\")                \n",
    "    return max_dict\n",
    "# Fucntion works (with print functions) BUT I bet there is a better/faster way...\n",
    "\n",
    "def Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict, poly_pixel_geom):\n",
    "    \"\"\"\n",
    "    This function deletes the poylgons from the geometry vectorized pixels that have not been identified as the \n",
    "    pixels with max elevation for each polyline. \n",
    "    Returns a subset/edited version of the provided \"poly_pixel_geom\" (will only work if the proper inputs have already been made)\n",
    "    \"\"\"\n",
    "    # grabbing the OBJECTID's and using these values to delete non-max associated polygons\n",
    "    Obj_ID_list = []\n",
    "    for item in max_dict.values():\n",
    "        # there are pixel polygons IDs that are duplicated in this list, only need to add them once (no need for repeating IDs)\n",
    "        if item[0] not in Obj_ID_list:\n",
    "            Obj_ID_list.append(item[0])\n",
    "\n",
    "    safety = 0\n",
    "    # deleteting polygons whose target_IDs are NOT the max_dict max_dict) \n",
    "    with arcpy.da.UpdateCursor(poly_pixel_geom, ['*']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[3] not in Obj_ID_list and safety < 4:\n",
    "    #             print(row[3])\n",
    "    #             safety +=1\n",
    "                cursor.deleteRow()\n",
    "\n",
    "    # still need to delete more pixel polygons if there do not conatin the max elevetion pre line...(slower than the above Search Cursor)\n",
    "    with arcpy.da.UpdateCursor(poly_pixel_geom, ['*']) as cursor:\n",
    "        for row in cursor:\n",
    "            # checking if the Target Id and the elevation are within the max_dict, if not delete the row\n",
    "            if row[3] not in max_dict[row[6]] and row[5] not in max_dict[row[6]]:\n",
    "                cursor.deleteRow()\n",
    "                \n",
    "######################################### Clip lines where they intersect MAX pixels ##########################################\n",
    "def Splitting_polylines_by_Max_Pixel_geom(poly_pixel_max_geom, intersection_geom, polylines_geom, Split_line_geom, max_dict):\n",
    "    # rename \"Target_FID\" col inside the vectorixed pixel geom features that have been spatialy joined with lines...\n",
    "    # make a new field then copy the old field values into the new one \n",
    "    arcpy.management.CalculateField(poly_pixel_max_geom, \"PIXEL_ID\", \"!TARGET_FID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "    # delete unnecessary columns\n",
    "    arcpy.management.DeleteField(poly_pixel_max_geom, \"TARGET_FID\", \"DELETE_FIELDS\")\n",
    "\n",
    "    # creating points that delinate the intersect of each line with each max polygon (creates points whenver each line intersect a polygon)\n",
    "    arcpy.analysis.Intersect([polylines_geom, poly_pixel_max_geom], \n",
    "                             intersection_geom, \n",
    "                             \"NO_FID\", \n",
    "                             None, \n",
    "                             \"POINT\")\n",
    "\n",
    "    # need to keep only one point per line that marks where each line intersects withits max elevation pixel/polygon\n",
    "    safety = 0\n",
    "    number_of_matches = 0\n",
    "    with arcpy.da.UpdateCursor(intersection_geom, ['gridcode', 'Degree', 'PIXEL_ID']) as cursor:\n",
    "        for row in cursor:\n",
    "            safety += 1\n",
    "            if safety < 10000:\n",
    "                degree = row[1]\n",
    "                #if pixel_id are equal and elevation values are equal keep\n",
    "                if  max_dict[degree][0] == row[2] and max_dict[degree][2] == row[0]:\n",
    "                    number_of_matches += 1\n",
    "                # else delete row\n",
    "                else:\n",
    "                    cursor.deleteRow()\n",
    "\n",
    "    print(\"Number of matches found:\", number_of_matches)      \n",
    "\n",
    "\n",
    "    # Split lines by points:\n",
    "    arcpy.management.SplitLineAtPoint(polylines_geom, \n",
    "                                      intersection_geom, \n",
    "                                      Split_line_geom, \n",
    "                                      None)\n",
    "\n",
    "    # delete polyline with ORG_SEG = 1 (delete lines that do not intersect with anchor point):\n",
    "    safety = 0\n",
    "    with arcpy.da.UpdateCursor(Split_line_geom, ['ORIG_SEQ']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == 1:\n",
    "                cursor.deleteRow()\n",
    "\n",
    "    # Successfully clipped lines!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Spatial Join between lines and DEM pixels Keeping Elevation Geom ###############################\n",
    "Poly_Int_Clip_DEM_SpJn = Creating_file_names(Output_Filepath, \"\\Poly_Int_Clip_DEM_SpJn\", Num_Image_Coords)\n",
    "\n",
    "# creating a Spatial Join where we keep the elevation geom: \n",
    "for poly_pixel, max_el, poly_SpJn in zip(poly_pixels_vw, max_elevation, Poly_Int_Clip_DEM_SpJn):\n",
    "    arcpy.analysis.SpatialJoin(poly_pixel, \n",
    "                               max_el, \n",
    "                               poly_SpJn, \n",
    "                               \"JOIN_ONE_TO_MANY\", \n",
    "                               \"KEEP_COMMON\", \n",
    "                               'gridcode \"gridcode\" true true false 4 Long 0 0,First,#,Poly_Int_Clip_DEM1,gridcode,-1,-1;'\\\n",
    "                               'Degree \"Degree\" true true false 19 Double 0 0,First,#,view1_lines_b,Degree,-1,-1;'\\\n",
    "                               'Line_ID \"Line_ID\" true true false 19 Double 0 0,First,#,view1_lines_b,Line_ID,-1,-1', \n",
    "                               \"INTERSECT\", \n",
    "                               None, \n",
    "                               '')\n",
    "# this takes a WHILE (at least 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Creating Max Dict. Iterated 7881231 times (lines x pixels in each viewshed)\n",
      "Done Creating Max Dict. Iterated 15475389 times (lines x pixels in each viewshed)\n",
      "Done Creating Max Dict. Iterated 20096613 times (lines x pixels in each viewshed)\n",
      "Done Creating Max Dict. Iterated 13940826 times (lines x pixels in each viewshed)\n",
      "Done Creating Max Dict. Iterated 13922790 times (lines x pixels in each viewshed)\n",
      "Done Creating Max Dict. Iterated 8151270 times (lines x pixels in each viewshed)\n"
     ]
    }
   ],
   "source": [
    "# indentifying MAX elevation for each polyline\n",
    "max_dict1 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev1\", \"Poly_Int_Clip_DEM_SpJn1\")\n",
    "max_dict2 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev2\", \"Poly_Int_Clip_DEM_SpJn2\")\n",
    "max_dict3 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev3\", \"Poly_Int_Clip_DEM_SpJn3\")\n",
    "max_dict4 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev4\", \"Poly_Int_Clip_DEM_SpJn4\")\n",
    "max_dict5 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev5\", \"Poly_Int_Clip_DEM_SpJn5\")\n",
    "max_dict6 = Identifying_Max_elevations_from_Poly_Pixels(\"lines_max_elev6\", \"Poly_Int_Clip_DEM_SpJn6\")\n",
    "# again, this can take a few minutes ~12 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting poylgons from the geometry pixels that have not been identified as the pixels with max elevation for each polyline\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict1, \"Poly_Int_Clip_DEM_SpJn1\")\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict2, \"Poly_Int_Clip_DEM_SpJn2\")\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict3, \"Poly_Int_Clip_DEM_SpJn3\")\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict4, \"Poly_Int_Clip_DEM_SpJn4\")\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict5, \"Poly_Int_Clip_DEM_SpJn5\")\n",
    "Keeping_poly_pixels_with_Max_Elevation_for_each_Polyline(max_dict6, \"Poly_Int_Clip_DEM_SpJn6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches found: 1553\n",
      "Number of matches found: 713\n",
      "Number of matches found: 655\n",
      "Number of matches found: 955\n",
      "Number of matches found: 766\n",
      "Number of matches found: 3539\n"
     ]
    }
   ],
   "source": [
    "# creating variables names for functions\n",
    "intersection_pts_names = Creating_file_names(Output_Filepath, \"\\lines_poly_Intersect\", Num_Image_Coords)\n",
    "Split_line_geom_names = Creating_file_names(Output_Filepath, \"\\lines_Split_view\", Num_Image_Coords)\n",
    "max_dicts = [max_dict1, max_dict2, max_dict3, max_dict4, max_dict5, max_dict6]\n",
    "\n",
    "# clipping lines based on their intersection with Max pixels for each line\n",
    "for pixel_geom, intersection_pts, max_lines, split_lines, dict_ in zip( Poly_Int_Clip_DEM_SpJn, intersection_pts_names, max_elevation, Split_line_geom_names, max_dicts):\n",
    "    splits = pixel_geom.split('\\\\')\n",
    "    name = splits[len(splits)-1]\n",
    "    splits_line = max_lines.split('\\\\')\n",
    "    name_line = splits_line[len(splits_line)-1]\n",
    "    string  = \"'\" + max_lines[len(max_lines)-len(name_line):len(max_lines)] +\"'\" + ' #;'+ \"'\"+ pixel_geom[len(pixel_geom)-len(name):len(pixel_geom)]+ \"'\" + ' #'\n",
    "    \n",
    "    Splitting_polylines_by_Max_Pixel_geom(pixel_geom, intersection_pts, max_lines, split_lines, dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Calculate Geometry (line Length) ###############################################\n",
    "for split_lines in Split_line_geom_names:\n",
    "    # Calculating Line Length for each line (geodesic) into a new column named \"LENGTH\"\n",
    "    arcpy.management.CalculateGeometryAttributes(split_lines, \n",
    "                                                 \"LENGTH LENGTH_GEODESIC\", \n",
    "                                                 \"KILOMETERS\", '', \n",
    "                                                 'GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \n",
    "                                                 \"SAME_AS_INPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Distances associated with each of the polyline as a csv...\n",
    "csvs_names = Creating_file_names(out_path, \"\\lines_Split_view\", Num_Image_Coords)\n",
    "\n",
    "edited_csv_list =[]\n",
    "for csv in csvs_names:\n",
    "    edited_csv_list.append(csv + \".csv\")\n",
    "\n",
    "for split_lines, csv in zip(Split_line_geom_names, edited_csv_list):\n",
    "    arcpy.conversion.ExportTable(split_lines, \n",
    "                                 csv, \n",
    "                                 '', \n",
    "                                 \"NOT_USE_ALIAS\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 501 501 501 501 501\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# a simply sanity check: length of each dict should eaqual 'Number of Polykines' a.k.a. 501\n",
    "print(len(max_dict1),len(max_dict2),len(max_dict3),len(max_dict4),len(max_dict5),len(max_dict6))\n",
    "\n",
    "# pprint(max_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
